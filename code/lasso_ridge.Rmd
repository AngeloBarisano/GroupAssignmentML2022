




```{r}
load("/home/angelo/Documents/Uni/Courses/Machine Learning & Algorithms/group_assignment/data/bookings_train.RData")
library("tidymodels")
library("themis")
library("knitr")
library("ranger")
library("doParallel")
library("vip")
library("skimr")
library("corrplot")
library("ggridges")
library("forcats")

require("lubridate")

load("/home/angelo/Documents/Uni/Courses/Machine Learning & Algorithms/group_assignment/data/bookings_test.RData")
```


```{r}
# convert to day of week 
tst <- c(bookings_train$arrival_date_month)
bookings_train$arrival_date_month_numb <- match(tst,month.name)

bookings_train$date_col <- as.Date(ISOdate(year = bookings_train$arrival_date_year, month = bookings_train$arrival_date_month_numb, day = bookings_train$arrival_date_day_of_month))

bookings_train$arrival_date_day_of_week <- wday(bookings_train$date_col)

bookings_train$arrival_date_day_of_week <- as.factor(bookings_train$arrival_date_day_of_week)



# reserved roomtype being equal 
bookings_train$got_reserved_room <- as.numeric(bookings_train$reserved_room_type == bookings_train$assigned_room_type)

bookings_train$got_reserved_room <- as.factor(bookings_train$got_reserved_room)


```


## Observe proportions in the original outcome
```{r}
bookings_train |> count(is_cancelled) |> 
  mutate(prop = n / sum(n))
bookings_train |> group_by(is_cancelled)|> knit_print()

```

```{r}
skim(bookings_train) |> group_by("is_cancelled") |> knit_print()
```

```{r}
# convert to factor 
bookings_train$arrival_date_year <- as.factor(bookings_train$arrival_date_year)
bookings_train$arrival_date_month <- as.factor(bookings_train$arrival_date_month)
bookings_train$arrival_date_week_number <- as.factor(bookings_train$arrival_date_week_number)
bookings_train$arrival_date_day_of_month <- as.factor(bookings_train$arrival_date_day_of_month)
bookings_train$reserved_room_type <- as.factor(bookings_train$reserved_room_type)
bookings_train$assigned_room_type <- as.factor(bookings_train$assigned_room_type)
bookings_train$country <- as.factor(bookings_train$country)

bookings_train$arrival_date_day_of_week <- as.numeric(bookings_train$arrival_date_day_of_week)
bookings_train$arrival_date_month_numb <- as.numeric(bookings_train$arrival_date_month_numb)
bookings_train$arrival_date_week_number <- as.numeric(bookings_train$arrival_date_week_number)

```

# Simple preprocsessing
```{r}
bookings_train$country <- fct_lump_min(as.factor(bookings_train$country), min=300, other_level = "Other")

# remove 0 visits
bookings_train <- bookings_train %>% 
  filter(!(stays_in_weekend_nights == 0 & stays_in_week_nights == 0))

bookings_train <- bookings_train %>% 
  filter(!(stays_in_weekend_nights == 0 & stays_in_week_nights == 0)) %>% 
  filter(adults != 0)

```

```{r}
# split the data
set.seed(42)
bookings_train_split <- initial_split(data = bookings_train, prop = 0.80, 
                          strata = is_cancelled)

# I keep the train in the name for a reason: this way we can differentiate between validation and test set later on
bookings_train_train <- training(bookings_train_split)
bookings_train_test <- testing(bookings_train_split)
print(bookings_train_train |> count(is_cancelled) |> 
  mutate(prop = n / sum(n)))
print(bookings_train_test |> count(is_cancelled) |> 
  mutate(prop = n / sum(n)))

```

```{r}


recipe_prelim <- recipe(is_cancelled ~ ., data = bookings_train_train) |> 
  update_role("country","assigned_room_type", "date_col", "arrival_date_month", "arrival_date_day_of_month", "adr", new_role = "metadata") |>
  step_other("reserved_room_type", "meal" , "market_segment") |>
  step_harmonic('arrival_date_day_of_week',frequency=1,cycle_size=7, role='predictor') |>
 # step_harmonic('arrival_date_week_number',frequency=1,cycle_size=53, role='predictor') |>
  step_harmonic('arrival_date_month_numb',frequency=1,cycle_size=12, role='predictor') |>          
  step_normalize(all_numeric_predictors())|>
  step_dummy(all_nominal_predictors())|>
  step_impute_mode(all_nominal_predictors()) |>
  step_impute_knn(all_numeric_predictors()) |>
  step_nzv() |>
  step_downsample("is_cancelled")

set.seed(82001)
cv_folds <- bookings_train_train |> vfold_cv(v = 3, strata = is_cancelled)


ridge_logreg <- logistic_reg(penalty = tune(), mixture = 0) |> 
  set_engine("glmnet")
lasso_logreg <- logistic_reg(penalty = tune(), mixture = 1) |> 
  set_engine("glmnet")



ridge_wf <- workflow() |> 
  add_recipe(recipe_prelim) |> 
  add_model(ridge_logreg)

lasso_wf <- workflow() |> 
  add_recipe(recipe_prelim) |> 
  add_model(lasso_logreg)


# metrics

class_metrics <- metric_set(accuracy, f_meas,bal_accuracy, kap, sensitivity, 
                            specificity, roc_auc, precision)
```




# grid for lasso/ ridge
```{r}
grid_lasso <- tibble(penalty = 10^(seq(from = -4.5, to = 5, length.out = 2)))

grid_ridge <- tibble(penalty = 10^(seq(from = -2.5, to = 5, length.out = 2)))

```


```{r}
lasso_tune <- lasso_wf |> 
  tune_grid(resamples = cv_folds, 
            grid = grid_lasso,
            metrics = class_metrics)
ridge_tune <- ridge_wf |> 
  tune_grid(resamples = cv_folds, 
            grid = grid_ridge,
            metrics = class_metrics)
```




```{r}
lasso_tune_metrics <- lasso_tune |> 
  collect_metrics()
lasso_tune_metrics |> filter(.metric == "accuracy") |> 
  ggplot(aes(x = penalty, y = mean, 
             ymin = mean - std_err, ymax = mean + std_err)) + 
  geom_errorbar(alpha = 0.5) + 
  geom_point() + 
  scale_x_log10() + 
  labs(y = "Accuracy", x = expression(lambda))
ridge_tune_metrics <- ridge_tune |> 
  collect_metrics()
ridge_tune_metrics |> filter(.metric == "accuracy") |> 
  ggplot(aes(x = penalty, y = mean, 
             ymin = mean - std_err, ymax = mean + std_err)) + 
  geom_errorbar(alpha = 0.5) + 
  geom_point() + 
  scale_x_log10() + 
  labs(y = "Accuracy", x = expression(lambda))
```


```{r}
lasso_1se_model <- lasso_tune |> 
  select_by_one_std_err(metric = "accuracy", desc(penalty))
lasso_1se_model
ridge_1se_model <- ridge_tune |> 
  select_by_one_std_err(metric = "accuracy", desc(penalty))
ridge_1se_model
```

# Finalize all workflows in order to start comparing them to each other
```{r}
lasso_wf_tuned <- 
  lasso_wf |> 
  finalize_workflow(lasso_1se_model)
lasso_wf_tuned
ridge_wf_tuned <- 
  ridge_wf |> 
  finalize_workflow(ridge_1se_model)
ridge_wf_tuned




```





# Test set performance

# Lasso/ ridge
```{r}
lasso_last_fit <- lasso_wf_tuned |> 
  last_fit(spam_split, metrics = class_metrics)
lasso_test_metrics <- lasso_last_fit |> collect_metrics()
lasso_test_metrics
ridge_last_fit <- ridge_wf_tuned |> 
  last_fit(spam_split, metrics = class_metrics)
ridge_test_metrics <- ridge_last_fit |> collect_metrics()
ridge_test_metrics
```


```{r}
lasso_test_metrics <- lasso_test_metrics |> 
  select(-.estimator, -.config) |> 
  mutate(model = "lasso")
ridge_test_metrics <- ridge_test_metrics |> 
  select(-.estimator, -.config) |> 
  mutate(model = "ridge")
load()
```

